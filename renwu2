"""
植物分类深度学习程序 
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import transforms, models
from torch.utils.data import Dataset, DataLoader, random_split
import pandas as pd
import numpy as np
from PIL import Image
import os
import glob
import random
from tqdm import tqdm
import warnings
warnings.filterwarnings('ignore')

# ==================== 配置参数 ====================
class Config:
    # 植物类别
    CLASS_NAMES = ['Black-grass', 'Common wheat', 'Loose Silky-bent', 
                   'Scentless Mayweed', 'Sugar beet']
    NUM_CLASSES = len(CLASS_NAMES)
    
    # 路径配置
    TRAIN_IMAGES_DIR = '/kaggle/input/renwu2/dataset-for-task2/dataset-for-task2/train'
    TEST_IMAGES_DIR = '/kaggle/input/renwu2/dataset-for-task2/dataset-for-task2/test'
    MODEL_SAVE_PATH = '/kaggle/working/plant_classifier.pth'
    OUTPUT_CSV = '/kaggle/working/submission.csv'
    
    # 训练参数
    BATCH_SIZE = 32
    NUM_EPOCHS = 20
    LEARNING_RATE = 0.001
    IMG_SIZE = 224
    VAL_SPLIT = 0.1
    
    # 设备
    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    # 数据增强
    train_transform = transforms.Compose([
        transforms.Resize((IMG_SIZE, IMG_SIZE)),
        transforms.RandomHorizontalFlip(p=0.5),
        transforms.RandomRotation(15),
        transforms.ColorJitter(brightness=0.2, contrast=0.2),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], 
                           std=[0.229, 0.224, 0.225])
    ])
    
    test_transform = transforms.Compose([
        transforms.Resize((IMG_SIZE, IMG_SIZE)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], 
                           std=[0.229, 0.224, 0.225])
    ])

# ==================== 数据集类 ====================
class PlantTrainDataset(Dataset):
    def __init__(self, data_dir, transform=None):
        self.data_dir = data_dir
        self.transform = transform
        self.image_paths = []
        self.labels = []
        
        print(f"扫描训练目录: {data_dir}")
        
        if not os.path.exists(data_dir):
            print(f"错误: 目录不存在")
            return
        
        for class_idx, class_name in enumerate(Config.CLASS_NAMES):
            class_dir = os.path.join(data_dir, class_name)
            if os.path.exists(class_dir):
                images = glob.glob(os.path.join(class_dir, '*.png'))
                images.extend(glob.glob(os.path.join(class_dir, '*.jpg')))
                images.extend(glob.glob(os.path.join(class_dir, '*.jpeg')))
                
                for img_path in images:
                    self.image_paths.append(img_path)
                    self.labels.append(class_idx)
                
                print(f"  {class_name}: {len(images)} 张")
        
        print(f"总计: {len(self.image_paths)} 张训练图片")
    
    def __len__(self):
        return len(self.image_paths)
    
    def __getitem__(self, idx):
        img_path = self.image_paths[idx]
        
        try:
            image = Image.open(img_path).convert('RGB')
            if self.transform:
                image = self.transform(image)
        except:
            image = torch.zeros(3, Config.IMG_SIZE, Config.IMG_SIZE)
        
        label = self.labels[idx]
        return image, label

class PlantTestDataset(Dataset):
    def __init__(self, images_dir, transform=None):
        self.images_dir = images_dir
        self.transform = transform
        self.image_paths = []
        
        print(f"扫描测试目录: {images_dir}")
        
        if not os.path.exists(images_dir):
            print(f"错误: 目录不存在")
            return
        
        # 查找所有图片
        images = glob.glob(os.path.join(images_dir, '*.png'))
        images.extend(glob.glob(os.path.join(images_dir, '*.jpg')))
        images.extend(glob.glob(os.path.join(images_dir, '*.jpeg')))
        
        self.image_paths = images
        self.image_names = [os.path.basename(p) for p in images]
        
        print(f"找到 {len(self.image_paths)} 张测试图片")
    
    def __len__(self):
        return len(self.image_paths)
    
    def __getitem__(self, idx):
        img_path = self.image_paths[idx]
        img_name = self.image_names[idx]
        
        try:
            image = Image.open(img_path).convert('RGB')
            if self.transform:
                image = self.transform(image)
        except:
            image = torch.zeros(3, Config.IMG_SIZE, Config.IMG_SIZE)
        
        return image, img_name

# ==================== 简化的模型定义 ====================
class SimplePlantClassifier(nn.Module):
    def __init__(self, num_classes=Config.NUM_CLASSES):
        super(SimplePlantClassifier, self).__init__()
        # 使用ResNet50
        self.model = models.resnet50(pretrained=True)
        
        # 冻结部分层
        for param in self.model.parameters():
            param.requires_grad = False
        
        # 解冻最后两层
        for param in self.model.layer4.parameters():
            param.requires_grad = True
        
        # 替换最后的全连接层
        num_features = self.model.fc.in_features
        self.model.fc = nn.Sequential(
            nn.Dropout(0.5),
            nn.Linear(num_features, num_classes)
        )
    
    def forward(self, x):
        return self.model(x)

# ==================== 训练函数 ====================
def train_model(model, train_loader, val_loader, num_epochs):
    model = model.to(Config.DEVICE)
    criterion = nn.CrossEntropyLoss()
    
    # 只训练需要梯度的参数
    optimizer = optim.Adam(
        filter(lambda p: p.requires_grad, model.parameters()),
        lr=Config.LEARNING_RATE
    )
    
    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)
    
    best_acc = 0.0
    
    for epoch in range(num_epochs):
        # 训练
        model.train()
        train_loss = 0.0
        correct = 0
        total = 0
        
        pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}')
        for images, labels in pbar:
            images = images.to(Config.DEVICE)
            labels = labels.to(Config.DEVICE)
            
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            
            train_loss += loss.item()
            _, predicted = outputs.max(1)
            total += labels.size(0)
            correct += predicted.eq(labels).sum().item()
            
            acc = 100. * correct / total
            pbar.set_postfix({'Loss': loss.item(), 'Acc': f'{acc:.2f}%'})
        
        scheduler.step()
        
        # 验证
        if val_loader:
            model.eval()
            val_correct = 0
            val_total = 0
            
            with torch.no_grad():
                for images, labels in val_loader:
                    images = images.to(Config.DEVICE)
                    labels = labels.to(Config.DEVICE)
                    
                    outputs = model(images)
                    _, predicted = outputs.max(1)
                    val_total += labels.size(0)
                    val_correct += predicted.eq(labels).sum().item()
            
            val_acc = 100. * val_correct / val_total
            
            print(f'Epoch {epoch+1}: 训练准确率: {acc:.2f}%, 验证准确率: {val_acc:.2f}%')
            
            if val_acc > best_acc:
                best_acc = val_acc
                torch.save(model.state_dict(), Config.MODEL_SAVE_PATH)
                print(f'  保存最佳模型，准确率: {val_acc:.2f}%')
        else:
            print(f'Epoch {epoch+1}: 训练准确率: {acc:.2f}%')
    
    return model

# ==================== 预测函数 ====================
def predict(model, test_loader):
    model.eval()
    predictions = []
    image_names = []
    
    with torch.no_grad():
        for images, names in tqdm(test_loader, desc='预测中'):
            images = images.to(Config.DEVICE)
            outputs = model(images)
            _, predicted = outputs.max(1)
            
            predictions.extend(predicted.cpu().numpy())
            image_names.extend(names)
    
    results = []
    for name, pred in zip(image_names, predictions):
        category = Config.CLASS_NAMES[pred]
        results.append([name, category])
    
    return results

# ==================== 主程序 ====================
def main():
    print("=" * 60)
    print("植物分类程序")
    print("=" * 60)
    
    # 删除旧的模型文件（如果存在）
    if os.path.exists(Config.MODEL_SAVE_PATH):
        print(f"删除旧的模型文件: {Config.MODEL_SAVE_PATH}")
        os.remove(Config.MODEL_SAVE_PATH)
    
    # 1. 准备数据
    print("\n1. 准备数据...")
    train_dataset = PlantTrainDataset(Config.TRAIN_IMAGES_DIR, Config.train_transform)
    
    if len(train_dataset) == 0:
        print("错误: 没有训练数据")
        return
    
    # 分割训练集和验证集
    val_size = int(Config.VAL_SPLIT * len(train_dataset))
    train_size = len(train_dataset) - val_size
    
    if val_size > 0:
        train_set, val_set = random_split(train_dataset, [train_size, val_size])
        train_loader = DataLoader(train_set, batch_size=Config.BATCH_SIZE, shuffle=True)
        val_loader = DataLoader(val_set, batch_size=Config.BATCH_SIZE, shuffle=False)
    else:
        train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)
        val_loader = None
    
    # 2. 训练模型
    print("\n2. 训练模型...")
    model = SimplePlantClassifier()
    
    # 检查是否有预训练模型
    if os.path.exists(Config.MODEL_SAVE_PATH):
        print(f"加载模型: {Config.MODEL_SAVE_PATH}")
        model.load_state_dict(torch.load(Config.MODEL_SAVE_PATH))
    else:
        print("开始训练...")
        model = train_model(model, train_loader, val_loader, Config.NUM_EPOCHS)
    
    # 3. 测试预测
    print("\n3. 准备测试数据...")
    test_dataset = PlantTestDataset(Config.TEST_IMAGES_DIR, Config.test_transform)
    
    if len(test_dataset) == 0:
        print("错误: 没有测试数据")
        return
    
    test_loader = DataLoader(test_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)
    
    # 4. 进行预测
    print("\n4. 进行预测...")
    predictions = predict(model, test_loader)
    
    # 5. 保存结果
    print("\n5. 保存结果...")
    df = pd.DataFrame(predictions, columns=['ID', 'Category'])
    df.to_csv(Config.OUTPUT_CSV, index=False)
    
    # 统计结果
    print(f"\n预测统计:")
    for class_name in Config.CLASS_NAMES:
        count = (df['Category'] == class_name).sum()
        print(f"  {class_name}: {count}")
    
    print(f"\n✅ 完成! 结果保存到: {Config.OUTPUT_CSV}")
    print(f"   共预测 {len(df)} 张图片")
    
    # 显示前10行
    print("\n前10行结果:")
    print(df.head(10).to_string(index=False))
    
    return df

# ==================== 程序入口 ====================
if __name__ == "__main__":
    # 检查路径
    if not os.path.exists(Config.TRAIN_IMAGES_DIR):
        print(f"训练目录不存在: {Config.TRAIN_IMAGES_DIR}")
        print("请检查路径设置")
    else:
        df = main()
    
    print("\n程序结束")
